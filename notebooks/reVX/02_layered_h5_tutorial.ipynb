{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoTIFFs to reV HDF5 Files\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "- Required: None\n",
    "- Recommended: [Working with GeoTIFFs](./01_geotiff_tutorial.ipynb)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the previous tutorial, we demonstrated how we can use `reVX`'s `Geotiff` handler to manage geotiff files.\n",
    "\n",
    "In this tutorial, we will go over getting TIFF files into a [reV](https://github.com/NREL/reV)-ready format using the `LayeredH5` handler.\n",
    "\n",
    "We'll cover the following steps:\n",
    "1. Creating a Layered HDF5 file using a GeoTIFF template\n",
    "2. Writing layers to the Layered HDF5 file\n",
    "3. Extracting layers from the Layered HDF5 file\n",
    "4. All of the above from the command line\n",
    "\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "Let's start with a few common imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "import h5py\n",
    "from reVX.handlers.layered_h5 import LayeredH5\n",
    "from reVX.handlers.geotiff import Geotiff\n",
    "\n",
    "from sl_utils import download_tiff_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# uncomment below if you want to see the contents of `download_tiff_file`\n",
    "# %load sl_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "Before we dive into the code, we first have to download a sample TIFF from \n",
    "[Siting Lab](https://data.openei.org/submissions/6119) to use as an example of adding data to a layered HDF5 file. \n",
    "In particular, we will be using data from {cite:ps}`oedi_6120`, {cite:ps}`oedi_6121`, {cite:ps}`oedi_6125`, and {cite:ps}`oedi_6132`.\n",
    "\n",
    "If you have already downloaded the data, you can skip this step (just make sure path variables below are set correctly).\n",
    "We'll start by defining the local file path destination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRPORT_HELIPORT_SETBACKS = \"airport_heliport_setbacks.tif\"\n",
    "NEXRAD_GREEN_LOS = \"NEXRAD_green_los.tif\"\n",
    "SETBACKS_PIPELINE_REFERENCE = \"setbacks_pipeline_reference.tif\"\n",
    "SETBACKS_STRUCTURE_115HH_170RD = \"setbacks_structure_115hh_170rd.tif\"\n",
    "SETBACKS_STRUCTURE_REFERENCE = \"setbacks_structure_reference.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define the URL for each of these files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_URLS = {\n",
    "    AIRPORT_HELIPORT_SETBACKS: \"https://data.openei.org/files/6120/airport_heliport_setbacks.tif\",\n",
    "    NEXRAD_GREEN_LOS: \"https://data.openei.org/files/6121/nexrad_4km.tif\",\n",
    "    SETBACKS_PIPELINE_REFERENCE: \"https://data.openei.org/files/6125/setbacks_pipeline_115hh_170rd_extrapolated.tif\",\n",
    "    SETBACKS_STRUCTURE_115HH_170RD: \"https://data.openei.org/files/6132/setbacks_structure_115hh_170rd_extrapolated.tif\",\n",
    "    SETBACKS_STRUCTURE_REFERENCE : \"https://data.openei.org/files/6132/setbacks_structure_115hh_170rd.tif\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use a siting lab utility function to download the data. This function uses `urllib` (which is part of the Python standard library) under the hood.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> The source TIFF files are large (90m resolution for all of CONUS), so we specified <code class=\"python\">crop=True</code> to crop the data immediately after downloading it to make it easier to work with. If you have a machine with sufficiently large memory (32GB+), or you are downloading the file in order to use it for analysis purposes, you should set <code class=\"python\">crop=False</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'airport_heliport_setbacks.tif' already exists!'NEXRAD_green_los.tif' already exists!\n",
      "'setbacks_pipeline_reference.tif' already exists!\n",
      "'setbacks_structure_115hh_170rd.tif' already exists!\n",
      "\n",
      "'setbacks_structure_reference.tif' already exists!\n"
     ]
    }
   ],
   "source": [
    "def download(local_filepath):\n",
    "    url = FILE_URLS[local_filepath]\n",
    "    download_tiff_file(url, local_filepath, crop=True)\n",
    "\n",
    "\n",
    "with ThreadPool(len(FILE_URLS)) as p:\n",
    "    p.map(download, FILE_URLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Layered HDF5 files\n",
    "\n",
    "In this section, we will outline some basic workflows using the `LayeredH5` class.\n",
    "\n",
    "### Creating the Layered HDF5 file from TIFF\n",
    "\n",
    "First, we will initialize the `LayeredH5` object.\n",
    "\n",
    "If creating a new HDF5 file that does not exist, we use the `.create_new()` method. \n",
    "\n",
    "When creating a new HDF5, a template filepath must be specified. The template file is used to define the properties of the HDF5 file including:\n",
    "\n",
    "1. The profile information\n",
    "2. Coordinate reference system and projection\n",
    "3. The geographic extent, spatial resolution\n",
    "\n",
    "All other files that are subsequently added to the HDF5 file will be transformed/adjusted to fit the properties of the template file before being written to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "H5_PATH = \"example.h5\"\n",
    "\n",
    "# Initialize layered h5 object\n",
    "h5 = LayeredH5(H5_PATH, template_file=NEXRAD_GREEN_LOS)\n",
    "\n",
    "# If file doesn't exist, create new h5\n",
    "h5.create_new()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the HDF5 file (using the `layers` property), we see that the first two layers are longitude and latitude arrays. These are the coordinate locations for each grid cell defined by the template file pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude', 'longitude']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the layer method to see the layers in the H5 file\n",
    "h5.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta data information about the HDF5 file can be retrieved by using `.profile` and `.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H5 profile: {'driver': 'GTiff', 'dtype': 'uint8', 'nodata': 255.0, 'width': 2000, 'height': 2000, 'count': 1, 'crs': '+init=epsg:5070', 'transform': (90.0, 0.0, 1829980.2632930684, 0.0, -90.0, 2297068.2309463923), 'blockxsize': 256, 'blockysize': 256, 'tiled': True, 'compress': 'lzma', 'interleave': 'band'}\n",
      "shape: (2000, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(f\"H5 profile: {h5.profile}\")\n",
    "print(f\"shape: {h5.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing layers to the HDF5 file\n",
    "\n",
    "Once the HDF5 file is created (or if it exists already), we can write NumPy arrays and TIFF files into the h5 files using the `.write_layer_to_h5()` and `.write_geotiff_to_h5()` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Adding numpy arrays\n",
    "with Geotiff(NEXRAD_GREEN_LOS) as geo:\n",
    "    h5.write_layer_to_h5(\n",
    "        values=geo.values,\n",
    "        layer_name=\"nexrad_green_los\",\n",
    "        profile=geo.profile,\n",
    "        description=\"NEXRAD Line of sight\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppinchuk/gitrepos/SitingLab/.pixi/envs/dev/lib/python3.11/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/home/ppinchuk/gitrepos/SitingLab/.pixi/envs/dev/lib/python3.11/site-packages/pyproj/crs/crs.py:1293: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n",
      "  proj = self._crs.to_proj4(version=version)\n"
     ]
    }
   ],
   "source": [
    "# Adding a geotiff file directly\n",
    "h5.write_geotiff_to_h5(\n",
    "    geotiff=AIRPORT_HELIPORT_SETBACKS,\n",
    "    layer_name=\"airport_heliport_setbacks\",\n",
    "    description=\"Setbacks from airports and heliports\",\n",
    "    replace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check to see what layers are currently in the HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airport_heliport_setbacks', 'latitude', 'longitude', 'nexrad_green_los']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking current layers in the\n",
    "h5.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add multiple GeoTIFFs into the h5 using the `.layers_to_h5()` method. This method accepts two types of inputs:\n",
    "\n",
    "1) A list of GeoTIFFs filepaths. In this case, the layer name in the HDF5 file will be the stem of the filename. \n",
    "2) A dictionary mapping layer names to GeoTIFFs filepaths. \n",
    "    \n",
    "Optionally, you can include a dictionary mapping layer names to layer descriptions (in text format) using the `description` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 3 file(s) to the h5...\n",
      "setbacks_pipeline_reference\n",
      "setbacks_structure_115hh_170rd\n",
      "setbacks_structure_reference\n"
     ]
    }
   ],
   "source": [
    "file_list = [\n",
    "    SETBACKS_PIPELINE_REFERENCE,\n",
    "    SETBACKS_STRUCTURE_115HH_170RD,\n",
    "    SETBACKS_STRUCTURE_REFERENCE,\n",
    "]\n",
    "\n",
    "print(f\"Adding {len(file_list)} file(s) to the h5...\")\n",
    "for fn in file_list:\n",
    "    print(fn.split(\".\")[0])\n",
    "\n",
    "h5.layers_to_h5(\n",
    "    layers=file_list,\n",
    "    replace=False,\n",
    "    descriptions={\n",
    "        \"setbacks_pipeline_reference\": \"This dataset represents wind energy \"\n",
    "        \"setback requirements from oil and gas pipelines. A setback \"\n",
    "        \"requirement is a minimum distance from a pipeline that an energy \"\n",
    "        \"project may be developed. As of April 2022, no ordinances were \"\n",
    "        \"discovered for any counties. Such ordinances are likely to arise as \"\n",
    "        \"regulations continue to expand. Therefore, this dataset applies a \"\n",
    "        \"median setback equivalent to 1.1 times the turbine tip-height, \"\n",
    "        \"sourced from trends in other infrastructure. The turbine parameters \"\n",
    "        \"used were a hub-height of 115 meters and a rotor diameter of 170 \"\n",
    "        \"meters, as obtained from the Annual Technology Baseline (ATB) 2022.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that our layers have indeed been added to the HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airport_heliport_setbacks',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'nexrad_green_los',\n",
       " 'setbacks_pipeline_reference',\n",
       " 'setbacks_structure_115hh_170rd',\n",
       " 'setbacks_structure_reference']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking current layers in the h5\n",
    "h5.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check that our description for `airport_heliport_setbacks` has been properly added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset represents wind energy setback requirements from oil and gas pipelines. A setback requirement is a minimum distance from a pipeline that an energy project may be developed. As of April 2022, no ordinances were discovered for any counties. Such ordinances are likely to arise as regulations continue to expand. Therefore, this dataset applies a median setback equivalent to 1.1 times the turbine tip-height, sourced from trends in other infrastructure. The turbine parameters used were a hub-height of 115 meters and a rotor diameter of 170 meters, as obtained from the Annual Technology Baseline (ATB) 2022.\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(H5_PATH) as h5_fh:\n",
    "    print(h5_fh[\"setbacks_pipeline_reference\"].attrs[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Layers from the HDF5 file\n",
    "\n",
    "Layers in the HDF5 file can also be extracted to GeoTIFFs. Simply call `.layer_to_geotiff()` to extract a single layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting a single layer\n",
    "layer = \"airport_heliport_setbacks\"\n",
    "out_filepath = \"airport_heliport_setbacks_h5_extract.tif\"\n",
    "h5.layer_to_geotiff(layer=layer, geotiff=out_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can call `.extract_layers()` to extract multiple layers. This method requires you to pass a dictionary mapping layer names to output filepaths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting multiple layers\n",
    "layers = {\n",
    "    \"nexrad_green_los\": \"nexrad_green_los_h5_extract.tif\",\n",
    "    \"setbacks_pipeline_reference\": \"setbacks_pipeline_reference_h5_extract.tif\"\n",
    "}\n",
    "h5.extract_layers(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the layers in the HDF5 can be extracted using the `.extract_all_layers()` method. To use it, simply pass an output directory where the extracted files should be written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5.extract_all_layers(out_dir=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layered HDF5 file via CLI\n",
    "\n",
    "Alternatively, the command line can be used to create, add to, and extract layers from the layered HDF5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding GeoTIFFs to the Layered HDF5 file\n",
    "\n",
    "First, we need to construct a JSON config file that contains layer name mapping to GeoTIFF filepaths.\n",
    "This JSON configuration file can optionally contain layer descriptions as a dictionary. For example, suppose we create a `layers.json` file with the following content:\n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"layers\":{\n",
    "        \"nexrad_green_los\": \"nexrad_green_los.tif\",\n",
    "        \"setbacks_pipeline_reference\": \"./setbacks_pipeline_reference.tif\"\n",
    "    },\n",
    "    \"descriptions\": {\n",
    "        \"setbacks_pipeline_reference\": \"This dataset represents wind energy setback requirements from oil and gas pipelines.\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Then we can run the following command: \n",
    "\n",
    "```bash\n",
    "$ reVX exclusions -h5 example_cli.h5 layers-to-h5 --layers layers.json\n",
    "```\n",
    "\n",
    "We can check wether the write was successful or not using the `h5ls` command (you may have to run `conda install h5py`):\n",
    "\n",
    "```bash\n",
    "$ h5ls example_cli.h5 \n",
    "latitude                 Dataset {2000, 2000}\n",
    "longitude                Dataset {2000, 2000}\n",
    "nexrad_green_los         Dataset {1, 2000, 2000}\n",
    "setbacks_pipeline_reference Dataset {1, 2000, 2000}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting GeoTIFF layers from the HDF5 file\n",
    "\n",
    "To extract layers from the h5 file, we pass a list of layers to extract as well as the desired output directory as arguments to the command:\n",
    "\n",
    "\n",
    "```bash\n",
    "$ mkdir data\n",
    "$ reVX exclusions -h5 example_cli.h5 layers-from-h5 -l nexrad_green_los,setbacks_pipeline_reference -o ./data\n",
    "```\n",
    "\n",
    "We can check wether the write was successful or not using the `h5ls` command (you may have to run `conda install h5py`):\n",
    "\n",
    "```bash\n",
    "$ ls data\n",
    "nexrad_green_los.tif  setbacks_pipeline_reference.tif\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this tutorial, we have walked through the basic steps to create and add to a Layered HDF5 file. This type of file is used primarily as the [exclusions layer input for reV supply curve aggregation](https://nrel.github.io/reV/_cli/reV%20supply-curve-aggregation.html#:~:text=%22INFO%22.-,excl_fpath,-str%20%7C%20list%20%7C%20tuple). You should now be able to:\n",
    "- Create a layered HDF5 file\n",
    "- Add layers to the HDF5 file\n",
    "- Extract layers from the HDF5 file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
